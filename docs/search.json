[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nMultivariate Analysis\n",
    "section": "",
    "text": "Data analysis is a vital part of every research work. To achieve this, there are three types of analysis that can be appliedto datasets, these includes:\n\nUnivariate analysis: This involves only one variable (methods includes mode, mean, median, etc.).\nBivariate analysis: This involves two variables (method includes linear regression, correlation etc. )\nMultivariate analysis: This involves two or more variables ( Cluster analysis, Principal Components or Factor analysis, neural network Bayesian classifier, matrix plot etc.). In multivariate analysis we are concerned with sets of objects on each of which p variables (or variates) are measured, but usually with no prior differentiation of variables into causes and effects. We can look at any one variable in isolation but to get the whole picture the variables must be considered jointly.\n\nMultivariate analysis(MVA) refers to a broad set of statistical methods designed for examining relationships among multiple variables concurrently, typically beyond two. Its purpose is to uncover intricate patterns and correlations within a dataset, offering a richer and more refined comprehension of the underlying scenario compared to simpler analyses. Through simultaneous examination of multiple variables, MVA yields deeper insights and more precise predictions, thereby bolstering decision-making within data-driven industries.\nIn fields like plant breeding, where understanding complex interconnections among data is crucial, this technique plays a foundation role. Variables such as days to flowering, days to maturity, 100_seed_weights and plant heights collectively influence the yield of crops. This necessitates the need for multivariate analysis.\nThere are several methods of multivariate analysis, but in this study, we will be considering three major methods:\n\nClustering\nK-means clustering, and\nPrincipal Component Analysis (PCA)."
  },
  {
    "objectID": "index.html#affiliation-international-institute-of-tropical-agriculture-iita",
    "href": "index.html#affiliation-international-institute-of-tropical-agriculture-iita",
    "title": "Introduction",
    "section": "affiliation: International Institute of Tropical Agriculture (IITA)",
    "text": "affiliation: International Institute of Tropical Agriculture (IITA)"
  },
  {
    "objectID": "index.html#partitioningcentroid-based-clustering",
    "href": "index.html#partitioningcentroid-based-clustering",
    "title": "\nMultivariate Analysis\n",
    "section": "1. Partitioning/Centroid based clustering",
    "text": "1. Partitioning/Centroid based clustering\nCentroid-based clustering is a clustering approach that divides a dataset into comparable groups by assessing the distances between their centroids. Example, k-means clustering."
  },
  {
    "objectID": "index.html#hierarchicalagglomerative-clustering",
    "href": "index.html#hierarchicalagglomerative-clustering",
    "title": "\nMultivariate Analysis\n",
    "section": "2. Hierarchical(Agglomerative) clustering",
    "text": "2. Hierarchical(Agglomerative) clustering\nThis method identifies clusters by evaluating the proximity of data points to each other, operating on the premise that objects in closer proximity are more closely associated than those situated farther apart. To apply connectivity-based clustering, you must first select the relevant data points and quantify their similarities or differences using a distance metric. Next, a connectivity measure, like a graph or network, is created to depict the connections among the data points. Subsequently, the clustering algorithm utilizes this connectivity data to organize the data points into clusters that capture their inherent similarities. This process is often represented visually through a dendrogram, resembling a hierarchical tree structure.\nThe Agglomerative clustering is the most common type of hierarchical clustering used to group objects in clusters based on their similarity. It’s also known as AGNES (Agglomerative Nesting). The algorithm starts by treating each object as a singleton cluster. Next, pairs of clusters are successively merged until all clusters have been merged into one big cluster containing all objects. The result is a tree-based representation of the objects, named dendrogram.\nA dendrogram shows the hierarchical relationship between the clusters\n\nThere are many distance metrics and the choice depends on the type of data:\n\nIf the data are continuous quantitative, we can use the Euclidean distance or that of Manhattan,\nIf the data is binary (categorical), we can use the Jaccard distance\nOther distance measurements include Minkowski, Canberra, etc.\n\nWhere there is no theoretical justification for an alternative, the Euclidean distance should generally be preferred. After the distance metric, we then have to choose a linkage criteria. There are many options: single-linkage, complete-linkage, mean or average-linkage, Ward’s method, etc. Each of the methods will produce a different dendrogram. In practice, we will most often prefer the Ward method. Ward’s method seeks to minimize intra-class variability and to maximize inter-class variability to obtain the most homogeneous possible clusters\nImportant things to note when working with Hierarchical clustering:\n\nStandardize the data: The variables to be used for clustering are of different units. Standardizing the data (mean zero, unit variance) will ensure that the data is at the same scale. We subtract each data from its mean and divide it by the standard deviation. We can use the scale () function in R\nDealing with missing values: Several ways to deal with these values,\n\ndelete them\nimpute them with a mean, median, mode or use advanced regression techniques.\n\n\nThe root of the dendrogram corresponds to the cluster with all the individuals together. This dendrogram represents a hierarchy of partitions. The “fusion” distance (height) is indicated on the y-axis of the dendrogram"
  },
  {
    "objectID": "index.html#grid-based-clustering",
    "href": "index.html#grid-based-clustering",
    "title": "\nMultivariate Analysis\n",
    "section": "3. Grid-Based clustering",
    "text": "3. Grid-Based clustering\nGrid-based clustering divides a high-dimensional dataset into cells, which are distinct sets of non-overlapping sub-regions. Every cell is given a unique identifier known as a cell ID, and all data points contained within a cell are regarded as belonging to the same cluster. This clustering technique proves efficient for analyzing expansive multidimensional datasets, as it diminishes the search time required for locating nearest neighbors, a frequent procedure in numerous clustering methodologies."
  },
  {
    "objectID": "index.html#density-based-clustering",
    "href": "index.html#density-based-clustering",
    "title": "\nMultivariate Analysis\n",
    "section": "4. Density-Based clustering",
    "text": "4. Density-Based clustering\nDensity-based clustering represents a robust unsupervised machine learning method that enables the identification of dense clusters within a dataset. In contrast to clustering algorithms like K-means and hierarchical clustering, density-based clustering can unveil clusters of varied shapes, sizes, and densities. This technique proves particularly advantageous when handling datasets containing noise or outliers, or when the precise number of clusters within the data is unknown."
  },
  {
    "objectID": "index.html#model-based-clustering",
    "href": "index.html#model-based-clustering",
    "title": "\nMultivariate Analysis\n",
    "section": "5. Model-Based clustering",
    "text": "5. Model-Based clustering\nModel-based clustering organizes data points into groups according to their probability distribution, leveraging statistical patterns to delineate clusters within the dataset. Unlike centroid-based clustering, it employs statistical patterns for cluster identification. However, model-based clustering is susceptible to overfitting, wherein clustering excessively relies on the dataset, leading to inaccurate predictions."
  },
  {
    "objectID": "index.html#example",
    "href": "index.html#example",
    "title": "\nMultivariate Analysis\n",
    "section": "Example",
    "text": "Example\nLet’s Consider the steptoe.morex.pheno.csv data from the agridat package, multi-environment trial of barley. The dataset contains 2432 observations on the following 10 variables:\n\ngen (genotype) - a Character vector for the genes of the barley\nenv (environment)- a character vector of the environment\namylase (alpha amylase), 20 Deg Units - a numeric vector for the alpha amylase sample\ndiapow (diastatic power), degree units - a numeric vector for the diastatic power\nhddate (heading date),julian days - a numeric vector for the heading date\nlodging, percent- a numeric vector for the lodging\nmalt (malt extract), percent - numeric vector for the malt sample\nheight (plant height), centimeters - numeric vector for the height sample\nprotein (grain protein), percent - numeric vector for the protein sample\nyield (grain yield), mt / ha - numeric vector for the plant yield\n\nLets take a look at a sample of the data\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\n#|message =FALSE\nlibrary(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndat &lt;- read_csv(\"steptoe.morex.pheno.csv\") \n\nRows: 2432 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): gen, env\ndbl (8): amylase, diapow, hddate, lodging, malt, height, protein, yield\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndat\n\n# A tibble: 2,432 × 10\n   gen     env   amylase diapow hddate lodging  malt height protein yield\n   &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 Steptoe MN92     22.7     46   150.      NA  73.6   84.5    10.5  5.53\n 2 Steptoe MTi92    30.1     72   178       10  76.5   NA      11.2  8.64\n 3 Steptoe MTd92    26.7     78   165       15  74.5   75.5    13.4  5.90\n 4 Steptoe ID91     26.2     74   179       NA  74.1  111      12.1  8.63\n 5 Steptoe OR91     19.6     62   191       NA  71.5   90      11.7  5.34\n 6 Steptoe WA91     23.6     54   181       NA  73.8  112      10    6.27\n 7 Steptoe MTi91    21       62   181       NA  70.8   98      12    4.10\n 8 Steptoe MTd91    NA       NA   181       NA  NA     82      NA    7.07\n 9 Steptoe NY92     NA       NA   176        0  NA     77.5    NA    6.05\n10 Steptoe ON92     NA       NA   198       50  NA     95      NA    3.70\n# ℹ 2,422 more rows\n\n\n\nstr(dat)\n\nspc_tbl_ [2,432 × 10] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ gen    : chr [1:2432] \"Steptoe\" \"Steptoe\" \"Steptoe\" \"Steptoe\" ...\n $ env    : chr [1:2432] \"MN92\" \"MTi92\" \"MTd92\" \"ID91\" ...\n $ amylase: num [1:2432] 22.7 30.1 26.7 26.2 19.6 23.6 21 NA NA NA ...\n $ diapow : num [1:2432] 46 72 78 74 62 54 62 NA NA NA ...\n $ hddate : num [1:2432] 150 178 165 179 191 ...\n $ lodging: num [1:2432] NA 10 15 NA NA NA NA NA 0 50 ...\n $ malt   : num [1:2432] 73.6 76.5 74.5 74.1 71.5 73.8 70.8 NA NA NA ...\n $ height : num [1:2432] 84.5 NA 75.5 111 90 112 98 82 77.5 95 ...\n $ protein: num [1:2432] 10.5 11.2 13.4 12.1 11.7 10 12 NA NA NA ...\n $ yield  : num [1:2432] 5.53 8.64 5.9 8.63 5.34 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   gen = col_character(),\n  ..   env = col_character(),\n  ..   amylase = col_double(),\n  ..   diapow = col_double(),\n  ..   hddate = col_double(),\n  ..   lodging = col_double(),\n  ..   malt = col_double(),\n  ..   height = col_double(),\n  ..   protein = col_double(),\n  ..   yield = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nThis shows us the structure and different data types in our dataset\nLet’s look at the summary of the data\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\nsummary(dat)\n\n     gen                env               amylase          diapow      \n Length:2432        Length:2432        Min.   :14.90   Min.   : 35.00  \n Class :character   Class :character   1st Qu.:25.62   1st Qu.: 70.00  \n Mode  :character   Mode  :character   Median :28.50   Median : 84.00  \n                                       Mean   :29.04   Mean   : 87.25  \n                                       3rd Qu.:32.00   3rd Qu.:101.00  \n                                       Max.   :49.30   Max.   :229.00  \n                                       NA's   :1066    NA's   :1066    \n     hddate         lodging            malt           height      \n Min.   :143.0   Min.   :  0.00   Min.   :69.00   Min.   : 34.00  \n 1st Qu.:174.5   1st Qu.: 15.00   1st Qu.:73.30   1st Qu.: 82.50  \n Median :183.5   Median : 35.00   Median :74.50   Median : 95.00  \n Mean   :181.2   Mean   : 37.13   Mean   :74.72   Mean   : 94.95  \n 3rd Qu.:191.0   3rd Qu.: 55.00   3rd Qu.:75.90   3rd Qu.:109.00  \n Max.   :217.0   Max.   :100.00   Max.   :83.00   Max.   :151.00  \n                 NA's   :1521     NA's   :1067    NA's   :5       \n    protein          yield       \n Min.   : 8.00   Min.   : 1.390  \n 1st Qu.:11.90   1st Qu.: 4.092  \n Median :13.00   Median : 5.272  \n Mean   :12.92   Mean   : 5.293  \n 3rd Qu.:14.00   3rd Qu.: 6.338  \n Max.   :17.50   Max.   :11.526  \n NA's   :1067                    \n\n\nWe have data from 17 environments\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\nlevels(dat$env)\n\nNULL\n\n\nLet’s consider only the env ID91\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.ID91 &lt;- dat %&gt;%   filter(env==\"ID91\")\n\nWe take a look at the summary of the data\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\nsummary(dat.ID91)\n\n     gen                env               amylase          diapow      \n Length:152         Length:152         Min.   :19.10   Min.   : 47.00  \n Class :character   Class :character   1st Qu.:25.48   1st Qu.: 72.00  \n Mode  :character   Mode  :character   Median :28.05   Median : 83.00  \n                                       Mean   :28.08   Mean   : 84.16  \n                                       3rd Qu.:30.12   3rd Qu.: 94.00  \n                                       Max.   :40.10   Max.   :144.00  \n                                                                       \n     hddate         lodging         malt           height         protein     \n Min.   :173.0   Min.   : NA   Min.   :71.10   Min.   : 92.7   Min.   :11.30  \n 1st Qu.:178.0   1st Qu.: NA   1st Qu.:73.40   1st Qu.:108.9   1st Qu.:12.90  \n Median :180.5   Median : NA   Median :74.40   Median :114.3   Median :13.50  \n Mean   :180.5   Mean   :NaN   Mean   :74.36   Mean   :114.0   Mean   :13.57  \n 3rd Qu.:183.0   3rd Qu.: NA   3rd Qu.:75.20   3rd Qu.:119.4   3rd Qu.:14.22  \n Max.   :188.0   Max.   : NA   Max.   :78.50   Max.   :137.2   Max.   :16.00  \n                 NA's   :152                                                  \n     yield       \n Min.   : 4.048  \n 1st Qu.: 6.681  \n Median : 7.684  \n Mean   : 7.500  \n 3rd Qu.: 8.382  \n Max.   :10.315  \n                 \n\n\nlodging is missing for all genotypes in this environment. So we exclude lodging in the dataset\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.ID91 &lt;- dat.ID91 %&gt;%   \n  select(-lodging) \n\nnames(dat.ID91)\n\n[1] \"gen\"     \"env\"     \"amylase\" \"diapow\"  \"hddate\"  \"malt\"    \"height\" \n[8] \"protein\" \"yield\"  \n\n\nNo more missing data, but it’s a good practice to use the function na.omit() and exclude any missing data the dataset may have\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.ID91 &lt;- na.omit(dat.ID91)\n\nLet’s store the names of the genotypes in a vector dat.ID91.label\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.ID91.label &lt;- dat.ID91$gen\n\nWe delete the gen and env columns from the dataset to only keep the quantitative variables\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.ID91$gen &lt;- NULL \ndat.ID91$env &lt;- NULL \ndat.ID91\n\n# A tibble: 152 × 7\n   amylase diapow hddate  malt height protein yield\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1    26.2     74   179   74.1   111     12.1  8.63\n 2    36.2     97   180   76.7   116     14.8  7.95\n 3    32.8     83   183   74.4   117.    14.3  6.10\n 4    24.9     81   178.  72.3   113     14    7.20\n 5    30.2     69   180   72.9   117.    13.8  6.01\n 6    30.3     99   184.  73.2   119.    14.9  8.09\n 7    33.4     63   178   73.5   104.    13.1  7.98\n 8    25.5     74   186.  71.8   130.    14.6  5.93\n 9    26.8     78   185   75     124.    12.8  8.72\n10    28.3     85   179   71.3   119.    14.1  6.48\n# ℹ 142 more rows\n\n\nThe data have different units. We standardize them using the function scale()\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.ID91.sc &lt;- scale(dat.ID91) \nsummary(dat.ID91.sc)\n\n    amylase              diapow             hddate              malt         \n Min.   :-2.323173   Min.   :-2.13347   Min.   :-2.13124   Min.   :-2.39465  \n 1st Qu.:-0.674579   1st Qu.:-0.69806   1st Qu.:-0.71724   1st Qu.:-0.70544  \n Median :-0.008677   Median :-0.06648   Median :-0.01023   Median : 0.02899  \n Mean   : 0.000000   Mean   : 0.00000   Mean   : 0.00000   Mean   : 0.00000  \n 3rd Qu.: 0.527924   3rd Qu.: 0.56510   3rd Qu.: 0.69677   3rd Qu.: 0.61654  \n Max.   : 3.107488   Max.   : 3.43592   Max.   : 2.11078   Max.   : 3.04018  \n     height            protein             yield        \n Min.   :-2.38931   Min.   :-2.44921   Min.   :-2.7274  \n 1st Qu.:-0.57607   1st Qu.:-0.72269   1st Qu.:-0.6471  \n Median : 0.02835   Median :-0.07525   Median : 0.1461  \n Mean   : 0.00000   Mean   : 0.00000   Mean   : 0.0000  \n 3rd Qu.: 0.59919   3rd Qu.: 0.70708   3rd Qu.: 0.6974  \n Max.   : 2.59152   Max.   : 2.62243   Max.   : 2.2246  \n\n\nThe distance metric is calculated using the Euclidean distance\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndist.ID91 &lt;- dist(dat.ID91.sc, method = 'euclidean')\n\nWe perform the hierarchical classification with the hclust () function and specify the method\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='large'\nhclust.ID91 &lt;- hclust(dist.ID91, method = 'ward.D2')\n\nWe can visualize the dendrogram using the plot() function\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='large'\nplot(hclust.ID91, hang = -1,rect= TRUE, cex = 0.5)   \n\nWarning in graphics:::plotHclust(n1, merge, height, order(x$order), hang, :\n\"rect\" is not a graphical parameter\nWarning in graphics:::plotHclust(n1, merge, height, order(x$order), hang, :\n\"rect\" is not a graphical parameter\n\n\nWarning in axis(2, at = pretty(range(height)), ...): \"rect\" is not a graphical\nparameter\n\n\nWarning in title(main = main, sub = sub, xlab = xlab, ylab = ylab, ...): \"rect\"\nis not a graphical parameter\n\n\n\n\n\n\n\n\n\nWe can visualize the three clusters with different colors by using the color_branches () function of the dendextend package\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\nlibrary(dendextend) \n\n\n---------------------\nWelcome to dendextend version 1.17.1\nType citation('dendextend') for how to cite the package.\n\nType browseVignettes(package = 'dendextend') for the package vignette.\nThe github page is: https://github.com/talgalili/dendextend/\n\nSuggestions and bug-reports can be submitted at: https://github.com/talgalili/dendextend/issues\nYou may ask questions at stackoverflow, use the r and dendextend tags: \n     https://stackoverflow.com/questions/tagged/dendextend\n\n    To suppress this message use:  suppressPackageStartupMessages(library(dendextend))\n---------------------\n\n\n\nAttaching package: 'dendextend'\n\n\nThe following object is masked from 'package:stats':\n\n    cutree\n\ndend.ID91 &lt;- as.dendrogram(hclust.ID91) \ncol.dend.ID91 &lt;- color_branches(dend.ID91, k = 3)\n\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\nplot(col.dend.ID91, hang = 1, cex = 0.4)  \n\nWarning in plot.window(...): \"hang\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"hang\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"hang\" is not a\ngraphical parameter\nWarning in axis(side = side, at = at, labels = labels, ...): \"hang\" is not a\ngraphical parameter\n\n\nWarning in title(...): \"hang\" is not a graphical parameter\n\n\n\n\n\n\n\n\n\nWe can get the groups to which the genotypes belong by specifying the number of clusters\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ncut.ID91 &lt;- cutree(hclust.ID91, k = 3)\n\nWe add the group names of the genotypes to the original data\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.ID91 &lt;- dat.ID91 %&gt;%  \n  mutate(cluster = cut.ID91)\n\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\n\ndat.ID91\n\n# A tibble: 152 × 8\n   amylase diapow hddate  malt height protein yield cluster\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;\n 1    26.2     74   179   74.1   111     12.1  8.63       1\n 2    36.2     97   180   76.7   116     14.8  7.95       2\n 3    32.8     83   183   74.4   117.    14.3  6.10       1\n 4    24.9     81   178.  72.3   113     14    7.20       1\n 5    30.2     69   180   72.9   117.    13.8  6.01       1\n 6    30.3     99   184.  73.2   119.    14.9  8.09       3\n 7    33.4     63   178   73.5   104.    13.1  7.98       1\n 8    25.5     74   186.  71.8   130.    14.6  5.93       3\n 9    26.8     78   185   75     124.    12.8  8.72       3\n10    28.3     85   179   71.3   119.    14.1  6.48       1\n# ℹ 142 more rows\n\n\nWe can aggregate the data based on groups\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.ID91.summary &lt;- dat.ID91 %&gt;%  \n  group_by(cluster) %&gt;%   summarize(     amylase=mean(amylase, na.rm=TRUE),     diapow=mean(diapow, na.rm=TRUE),     hddate=mean(hddate, na.rm=TRUE),     malt=mean(malt, na.rm=TRUE),     height=mean(height, na.rm=TRUE),     protein=mean(protein, na.rm=TRUE),     yield=mean(yield, na.rm=TRUE),     Nobs=n()   ) \n\ndat.ID91.summary\n\n# A tibble: 3 × 9\n  cluster amylase diapow hddate  malt height protein yield  Nobs\n    &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1       1    26.6   75.7   179.  74.0   110.    13.3  7.71    86\n2       2    33.9  110.    179.  74.6   115.    14.8  6.24    17\n3       3    28.6   89.9   184.  74.9   121.    13.5  7.56    49\n\n\nThe table above shows the summary of mean of each variable based on the cluster. This example illustrates how clustering into groups can be done in R."
  },
  {
    "objectID": "index.html#k-means-clustering-steps",
    "href": "index.html#k-means-clustering-steps",
    "title": "\nMultivariate Analysis\n",
    "section": "K-Means Clustering Steps",
    "text": "K-Means Clustering Steps\nConceptually, K-means operates in the following manner:\n\nIt randomly selects K centroids.\nEach data point (e.g., each yield) is assigned to the closest centroid in an n-dimensional space, where n represents the number of features used in clustering (e.g., features such as water, protein, oil, and height). This allocation results in each point belonging to a specific group.\nThe centroids are recalculated as the mean point (vector) of all other points within the group.\nSteps 2 and 3 are iteratively repeated until either the groups stabilize, meaning no points are reassigned to another centroid, or the maximum number of iterations is reached (commonly set to 10 in default settings).\n\nAs you increase the chosen value of K in clustering, the variance within the groups decreases. When K equals the number of observations, each point becomes its own group, resulting in a variance of 0.\nThe function kmeans() in the base R stats package can be used to perform K-means clustering. It is often recommended to use the set.seed() function to set a seed for R’s random number to make the results reproducible.\nThe basic argument of the function is as follows:\n\nkmeans(df, k, nstart = x)\n\ndf is the numeric data frame\nk is the number of clusters\nnstart =x is the number of random starting partitions, where x&gt;1 is recommended to have a stable result However, a beautiful cluster visualization can be created from the clusters generated with kmeans() function with fviz_cluster() function in the factoextra package which can be installed using install.packages(\"factoextra\").\n\n\nThe basic argument needed in the function are:\n\nfviz_cluster(km, df)\n\nkm is the kmeans object results\ndf is the original data sets"
  },
  {
    "objectID": "index.html#example-1",
    "href": "index.html#example-1",
    "title": "\nMultivariate Analysis\n",
    "section": "Example",
    "text": "Example\nTo demonstrate how these functions work, let’s consider steptoe.morex.pheno.csv dataset, a multi-environment trial of barley using one environment ,ID91.\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\nlibrary(tidyverse) \ndat &lt;- read_csv(\"steptoe.morex.pheno.csv\") \n\nRows: 2432 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): gen, env\ndbl (8): amylase, diapow, hddate, lodging, malt, height, protein, yield\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndat\n\n# A tibble: 2,432 × 10\n   gen     env   amylase diapow hddate lodging  malt height protein yield\n   &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 Steptoe MN92     22.7     46   150.      NA  73.6   84.5    10.5  5.53\n 2 Steptoe MTi92    30.1     72   178       10  76.5   NA      11.2  8.64\n 3 Steptoe MTd92    26.7     78   165       15  74.5   75.5    13.4  5.90\n 4 Steptoe ID91     26.2     74   179       NA  74.1  111      12.1  8.63\n 5 Steptoe OR91     19.6     62   191       NA  71.5   90      11.7  5.34\n 6 Steptoe WA91     23.6     54   181       NA  73.8  112      10    6.27\n 7 Steptoe MTi91    21       62   181       NA  70.8   98      12    4.10\n 8 Steptoe MTd91    NA       NA   181       NA  NA     82      NA    7.07\n 9 Steptoe NY92     NA       NA   176        0  NA     77.5    NA    6.05\n10 Steptoe ON92     NA       NA   198       50  NA     95      NA    3.70\n# ℹ 2,422 more rows\n\n\nFilter the data set to include only the quantitative variables and the genotype name.\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.ID91 &lt;- dat %&gt;%                     \n  filter(env==\"ID91\") %&gt;%                   \n  select(-c(env, lodging)) %&gt;%                  \n  column_to_rownames(var = \"gen\")\nhead(dat.ID91, 4)\n\n        amylase diapow hddate malt height protein yield\nSteptoe    26.2     74  179.0 74.1  111.0    12.1 8.629\nMorex      36.2     97  180.0 76.7  116.0    14.8 7.951\nSM1        32.8     83  183.0 74.4  116.8    14.3 6.095\nSM2        24.9     81  178.5 72.3  113.0    14.0 7.201\n\n\nTo Scale and compute the Euclidean distance\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.ID91.sc &lt;- dist(scale(dat.ID91), method = \"euclidean\")\n\nThis has scaled the dataset using the euclidean distance\nTo Compute K-means (Assuming 3 clusters)\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\nset.seed(234) \nk.means.ID91 &lt;- kmeans(dat.ID91.sc, 5, nstart=30) \n\nTo Compute Cluster number for each of the observations\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\n#|include = TRUE\nhead(k.means.ID91$cluster)\n\nSteptoe   Morex     SM1     SM2     SM3     SM4 \n      3       5       4       3       3       4 \n\n\nThis shows the cluster number for each observations.\nTo Compute Cluster size\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\nk.means.ID91$size\n\n[1] 25 17 52 39 19\n\n\nTo Compute Cluster means\n\n#|results = 'hide'\n\nk.means.ID91$centers \n\n   Steptoe    Morex      SM1      SM2      SM3      SM4      SM5      SM6\n1 2.396687 5.004639 4.571804 3.739524 4.164901 4.743407 3.484430 5.505864\n2 4.613283 4.708417 2.887331 3.359112 2.904901 3.081409 4.701587 2.362378\n3 2.472232 4.097363 3.100510 2.267613 2.592313 3.345960 2.656369 4.175304\n4 3.056281 3.367537 2.532194 3.050635 2.950751 2.540108 3.566628 3.685265\n5 4.849363 2.845180 3.091142 4.272241 3.921943 3.405148 4.321012 5.166986\n       SM7      SM8     SM10     SM11     SM12     SM13     SM14     SM15\n1 3.377673 4.729840 5.858328 5.845756 3.093984 3.915040 4.165559 3.641892\n2 3.761834 2.932933 5.772836 3.341753 6.431597 3.533855 5.328559 4.356080\n3 3.371636 3.009288 5.297382 4.189723 4.521166 2.415629 3.095047 3.785390\n4 2.285318 3.407485 4.463236 3.507704 4.591748 2.640392 3.941457 2.575791\n5 4.716943 4.180028 4.164572 3.106612 6.612834 3.400839 3.737706 4.766804\n      SM16     SM20     SM21     SM22     SM23     SM24     SM25     SM27\n1 3.585691 3.603773 6.219806 2.687926 4.576930 4.139708 3.805060 2.886406\n2 3.448935 3.253567 3.115514 4.703059 4.027034 3.779249 4.736979 4.183666\n3 2.436016 2.252891 4.327435 2.953940 3.626814 3.292979 2.478023 2.503625\n4 2.669671 2.932926 4.366398 3.585524 2.653918 2.281647 3.853368 2.904471\n5 4.052189 4.378637 4.412515 5.484264 2.803602 3.053269 4.047591 4.512935\n      SM30     SM31     SM32     SM35     SM39     SM40     SM41     SM42\n1 3.341203 4.025472 5.804181 3.711233 4.314046 2.574429 3.958372 3.559316\n2 4.620347 3.094947 2.928820 2.871918 2.960659 5.544522 3.359294 3.901436\n3 3.214442 3.392832 4.715422 2.920308 2.737046 3.156670 2.958033 2.361854\n4 2.522279 2.109101 3.888931 2.197635 2.588492 3.898445 2.754923 2.533089\n5 3.993640 4.002475 4.836671 4.212964 3.272273 5.543254 4.400415 2.954443\n      SM43     SM44     SM45     SM46     SM48     SM50     SM54     SM55\n1 4.328402 2.799742 4.694623 5.175809 3.039891 4.373829 4.266965 3.210410\n2 2.818472 4.953306 4.690091 2.380346 5.902977 3.871267 4.384680 6.826313\n3 3.294786 3.548127 4.360445 3.733202 3.139010 2.688485 2.718687 4.593150\n4 3.259252 3.011376 3.217466 3.369213 4.266631 3.537162 3.618615 5.102594\n5 5.142157 5.149806 3.696094 4.471447 4.974133 3.590026 3.462788 6.922808\n      SM56     SM57     SM58     SM59     SM61     SM62     SM63     SM64\n1 3.746131 3.747449 5.170813 6.330523 6.129453 3.124664 3.868063 2.576326\n2 6.037486 3.210362 3.556734 5.338485 3.717112 3.643771 3.105443 4.326862\n3 4.632332 3.219003 4.383890 5.080848 4.438914 2.636916 2.322926 2.090883\n4 4.091388 2.058619 2.975361 4.479530 4.014283 2.705336 2.712943 2.675110\n5 5.705687 3.986445 3.900421 3.463434 3.096258 4.856264 3.763578 4.089438\n      SM65     SM67     SM68     SM69     SM70     SM71     SM72     SM73\n1 2.680259 2.731785 4.611551 2.593370 2.866557 3.288146 2.939807 2.565014\n2 3.995858 5.956535 2.701018 4.220158 4.149401 4.676179 5.598812 6.141595\n3 2.129468 3.606008 3.540216 2.378521 2.380725 3.442754 3.207767 3.497301\n4 2.424626 4.166062 2.385629 2.473334 3.188349 4.147845 3.968873 4.190772\n5 3.878175 5.691834 3.802861 4.322468 5.043712 6.267425 5.221343 5.580213\n      SM74     SM75     SM76     SM77     SM78     SM79     SM80     SM81\n1 2.974352 2.891878 4.180747 3.743995 3.079250 3.843694 3.943767 5.936876\n2 4.658389 4.136422 3.591138 3.279511 4.305088 5.130702 3.058291 3.150492\n3 2.633188 2.517060 3.517585 3.209317 3.044511 3.143785 2.399386 4.979184\n4 2.949996 3.024949 2.259048 1.978014 2.267641 3.818870 2.270566 4.042762\n5 4.028085 4.907337 3.573715 3.941131 3.961778 3.907669 3.093824 5.110337\n      SM82     SM83     SM84     SM85     SM87     SM88     SM89     SM91\n1 5.245064 2.697712 3.671950 3.217101 3.705077 3.970364 4.631481 3.278259\n2 4.460648 5.268359 3.372302 4.072740 2.798809 4.086020 2.476646 4.716045\n3 3.669274 2.913396 2.892717 2.578328 2.684152 2.600272 3.513264 3.429108\n4 3.597352 3.549573 2.149481 3.495687 2.039860 3.345175 2.472469 2.502008\n5 2.387619 5.081318 3.784449 5.005707 3.715558 3.850742 3.947927 4.110468\n      SM92     SM93     SM94     SM97     SM98     SM99    SM103    SM104\n1 3.826594 4.014452 3.441179 2.969140 5.412136 4.849632 3.820744 5.124762\n2 3.676797 3.538520 4.311058 4.113355 4.290556 2.220715 3.303823 2.715120\n3 2.378610 2.828257 2.367192 2.123951 3.973663 3.673818 2.601610 3.940288\n4 2.967391 3.460231 2.892230 2.817669 3.564064 2.898455 2.038549 2.662547\n5 3.611958 4.914213 3.382529 4.124261 2.664677 4.494853 3.071857 3.726521\n     SM105    SM110    SM112    SM116    SM120    SM124    SM125    SM126\n1 2.948235 2.925165 3.679401 3.534775 3.653204 5.305968 4.038345 2.955469\n2 4.177425 4.786013 4.642656 4.010544 3.263226 2.344811 3.275675 5.004850\n3 3.061578 2.572071 2.872460 2.639887 2.439244 3.730096 3.074949 3.107199\n4 2.268103 2.949404 3.741603 2.416094 2.798331 3.268174 2.831299 4.089638\n5 4.276337 4.061838 4.877317 3.457748 4.021827 4.337137 4.756618 6.005346\n     SM127    SM129    SM130    SM131    SM132    SM133    SM134    SM135\n1 6.465125 3.003101 4.640955 3.098030 4.591152 2.871702 5.381253 3.109502\n2 5.885256 5.427067 4.482591 5.253060 3.340734 5.088618 4.232544 4.398164\n3 5.380929 3.134749 3.188355 3.686494 3.753789 2.784266 4.321386 2.536647\n4 4.820273 4.255851 3.543640 3.339856 2.584685 4.122702 3.267191 2.747073\n5 3.129551 5.838884 2.703092 5.001209 4.014572 5.525444 2.720119 3.675877\n     SM136    SM137    SM139    SM140    SM141    SM142    SM143    SM144\n1 2.694613 5.185676 3.239424 2.849002 3.380047 3.552024 5.459776 3.373386\n2 4.593214 2.609539 4.911377 4.471188 4.394931 4.950179 5.026826 3.117931\n3 3.000104 3.933054 2.680430 3.175977 3.452107 4.044813 3.942597 2.792939\n4 2.809172 3.792723 3.636737 2.420272 2.367410 2.999566 4.305046 1.996600\n5 4.961074 5.243681 4.505711 4.568721 4.052924 4.642122 2.898851 4.127303\n     SM145    SM146    SM147    SM149    SM150    SM151    SM152    SM153\n1 4.332509 3.322741 4.020953 3.333693 3.206997 5.182178 4.048625 2.303564\n2 3.267985 3.175907 3.525092 5.915102 3.646024 2.703152 2.763140 5.155989\n3 3.245122 2.367345 3.363378 3.213869 2.471414 3.992624 2.569924 2.893010\n4 2.246689 2.516852 2.277741 4.094691 3.058366 3.085806 2.175991 3.357354\n5 3.523356 4.291719 3.814893 4.591378 4.912281 4.257375 3.125863 5.192849\n     SM154    SM155    SM156    SM157    SM158    SM159    SM160    SM161\n1 4.509202 2.672747 5.448283 3.450132 4.588278 2.875706 2.802902 3.119339\n2 3.851159 5.342529 3.576348 4.521674 4.323639 3.562176 4.149623 5.487960\n3 3.259915 3.027247 3.823503 2.819375 3.291105 2.205395 2.477301 3.710065\n4 2.922540 3.641573 3.240762 2.734964 3.630021 2.755942 3.085863 4.610606\n5 3.377658 4.866790 2.403132 3.788803 3.299429 4.674165 4.984653 6.686289\n     SM162    SM164    SM165    SM166    SM167    SM168    SM169    SM170\n1 2.755081 3.753454 4.258295 3.393463 2.640478 3.433762 6.109715 5.490770\n2 4.022190 3.263644 2.772031 4.188518 4.602688 3.870671 2.987348 5.029022\n3 2.207081 2.231881 2.912563 3.240574 2.571904 2.240267 4.901853 4.200985\n4 2.743424 2.940910 2.502517 3.692759 2.876159 3.188274 4.199235 3.875276\n5 4.339059 3.969481 3.915703 5.700302 4.361319 4.349172 5.562371 2.658428\n     SM171    SM172    SM173    SM174    SM176    SM177    SM179    SM180\n1 5.120731 3.314762 7.255712 3.295590 4.196696 4.183756 2.554746 3.690483\n2 3.938358 3.495428 4.448035 3.568807 4.136658 3.552283 4.378937 4.877201\n3 3.559662 2.756151 5.688933 3.052359 2.522772 2.431226 2.659036 2.652062\n4 3.245616 2.463715 4.767321 2.319259 3.707437 2.992329 2.733930 3.614644\n5 2.806904 4.522220 3.765605 4.434684 3.857640 3.263724 4.789590 3.760928\n     SM181    SM182    SM183    SM184    SM185    SM186    SM187    SM188\n1 2.636574 4.722798 4.150572 4.372638 5.031470 3.324758 4.960900 3.147702\n2 5.092511 3.031655 5.384845 4.455293 5.149013 3.752696 4.643482 3.803947\n3 2.891897 3.859840 3.094557 3.050965 3.508070 2.418554 3.545145 2.044142\n4 3.502989 2.812919 4.132580 4.226019 4.684261 2.109699 3.766593 2.791639\n5 4.990387 4.354504 4.114194 4.864945 4.447002 3.331631 2.710339 3.862386\n     SM189    SM193    SM194    SM196    SM197    SM198    SM199    SM200\n1 2.753970 3.531382 3.872170 6.567699 2.768062 5.441438 3.182296 3.482618\n2 4.814751 3.494119 3.567584 3.034679 4.793369 3.080450 3.747422 3.888391\n3 3.502063 2.490469 3.365734 4.857583 2.436951 4.116617 2.548198 2.132005\n4 2.867611 3.189412 2.613438 4.231959 3.274317 3.646322 2.464380 3.009706\n5 5.083762 4.913707 4.719238 4.236381 4.489983 4.457939 3.847091 3.820291\n\n\n\n#|results = 'hide\nset.seed(123) \nclustering &lt;- kmeans(dat.ID91.sc, centers = 2, nstart = 10)  \n\nUsing 3 group ( k = 3) we had 41.4% of well-grouped data.\nLets increase the value of k to 4 and compare the results.\n\n#|results = 'hide'\nset.seed(123) \nclustering &lt;- kmeans(dat.ID91.sc, centers = 4, nstart = 10) \nclustering  \n\nK-means clustering with 4 clusters of sizes 31, 54, 25, 42\n\nCluster means:\n   Steptoe    Morex      SM1      SM2      SM3      SM4      SM5      SM6\n1 4.862257 3.641589 3.058106 4.016133 3.599531 3.367044 4.576156 4.087150\n2 2.485849 4.098854 3.083015 2.266269 2.570197 3.335177 2.668772 4.143384\n3 2.396687 5.004639 4.571804 3.739524 4.164901 4.743407 3.484430 5.505864\n4 3.174975 3.435023 2.536055 3.054512 2.938184 2.515667 3.649556 3.541188\n       SM7      SM8     SM10     SM11     SM12     SM13     SM14     SM15\n1 4.445262 3.784596 4.784184 3.169714 6.659612 3.558766 4.419209 4.696990\n2 3.364790 2.960025 5.301235 4.173295 4.537585 2.425007 3.126527 3.785469\n3 3.377673 4.729840 5.858328 5.845756 3.093984 3.915040 4.165559 3.641892\n4 2.345804 3.368844 4.576637 3.497200 4.706720 2.666841 4.057934 2.664208\n      SM16     SM20     SM21     SM22     SM23     SM24     SM25     SM27\n1 3.879416 4.040838 3.875322 5.287676 3.337308 3.379272 4.403429 4.506773\n2 2.438731 2.254445 4.302118 2.965898 3.622727 3.288235 2.501179 2.513688\n3 3.585691 3.603773 6.219806 2.687926 4.576930 4.139708 3.805060 2.886406\n4 2.725240 2.929361 4.277818 3.655164 2.731937 2.384675 3.928605 2.973377\n      SM30     SM31     SM32     SM35     SM39     SM40     SM41     SM42\n1 4.344182 3.755449 4.031684 3.807821 3.239242 5.645107 4.122088 3.402232\n2 3.232330 3.382077 4.677315 2.903975 2.725413 3.179367 2.955079 2.361281\n3 3.341203 4.025472 5.804181 3.711233 4.314046 2.574429 3.958372 3.559316\n4 2.636416 2.102198 3.833326 2.180371 2.576027 4.025731 2.728967 2.644936\n      SM43     SM44     SM45     SM46     SM48     SM50     SM54     SM55\n1 4.354340 5.165840 4.147477 3.667285 5.441025 3.725041 3.913090 7.005582\n2 3.283289 3.563193 4.345887 3.692274 3.174172 2.687114 2.727138 4.621963\n3 4.328402 2.799742 4.694623 5.175809 3.039891 4.373829 4.266965 3.210410\n4 3.137442 3.129650 3.307903 3.282870 4.390696 3.599814 3.672833 5.206347\n      SM56     SM57     SM58     SM59     SM61     SM62     SM63     SM64\n1 5.912280 3.760076 3.843889 4.225958 3.332953 4.473043 3.591134 4.301764\n2 4.651657 3.203956 4.364669 5.082127 4.412119 2.650307 2.318965 2.114576\n3 3.746131 3.747449 5.170813 6.330523 6.129453 3.124664 3.868063 2.576326\n4 4.214775 2.105164 2.945742 4.524421 3.995819 2.739521 2.722577 2.780224\n      SM65     SM67     SM68     SM69     SM70     SM71     SM72     SM73\n1 4.012221 5.921221 3.400764 4.400145 4.815621 5.749247 5.475715 5.907708\n2 2.132519 3.631948 3.521054 2.403154 2.401759 3.451180 3.241274 3.530907\n3 2.680259 2.731785 4.611551 2.593370 2.866557 3.288146 2.939807 2.565014\n4 2.556495 4.278849 2.374805 2.567569 3.227010 4.161308 4.076174 4.331500\n      SM74     SM75     SM76     SM77     SM78     SM79     SM80     SM81\n1 4.348545 4.685566 3.633602 3.774011 4.172923 4.453238 3.166166 4.303431\n2 2.656062 2.535688 3.504208 3.199485 3.044880 3.150355 2.388919 4.943567\n3 2.974352 2.891878 4.180747 3.743995 3.079250 3.843694 3.943767 5.936876\n4 3.082609 3.100929 2.335674 2.021279 2.414969 3.945497 2.308118 3.973359\n      SM82     SM83     SM84     SM85     SM87     SM88     SM89     SM91\n1 3.234819 5.258774 3.685794 4.708435 3.433765 3.996833 3.427846 4.431890\n2 3.666931 2.946338 2.890384 2.578270 2.668591 2.603573 3.490649 3.437943\n3 5.245064 2.697712 3.671950 3.217101 3.705077 3.970364 4.631481 3.278259\n4 3.666693 3.664592 2.217723 3.560995 2.065600 3.423992 2.415985 2.645860\n      SM92     SM93     SM94     SM97     SM98     SM99    SM103    SM104\n1 3.695705 4.482914 3.845477 4.222069 3.344950 3.634662 3.234026 3.438167\n2 2.392259 2.817955 2.388863 2.137565 3.974740 3.644443 2.597481 3.919323\n3 3.826594 4.014452 3.441179 2.969140 5.412136 4.849632 3.820744 5.124762\n4 3.019045 3.438176 2.981872 2.912140 3.592093 2.803767 2.114253 2.558777\n     SM105    SM110    SM112    SM116    SM120    SM124    SM125    SM126\n1 4.314255 4.447076 4.913735 3.738163 3.787683 3.591312 4.291204 5.721159\n2 3.060625 2.588415 2.901820 2.653809 2.420251 3.696904 3.073891 3.133958\n3 2.948235 2.925165 3.679401 3.534775 3.653204 5.305968 4.038345 2.955469\n4 2.402598 3.087568 3.758584 2.528321 2.851272 3.160182 2.794352 4.134872\n     SM127    SM129    SM130    SM131    SM132    SM133    SM134    SM135\n1 4.222097 5.790868 3.429215 5.170272 3.787778 5.448626 3.346556 4.033143\n2 5.377097 3.169405 3.184281 3.688213 3.737928 2.805372 4.304699 2.536319\n3 6.465125 3.003101 4.640955 3.098030 4.591152 2.871702 5.381253 3.109502\n4 4.906227 4.321888 3.650056 3.496075 2.614282 4.206182 3.323120 2.896745\n     SM136    SM137    SM139    SM140    SM141    SM142    SM143    SM144\n1 4.908612 4.198936 4.748536 4.643110 4.272569 4.832359 3.744466 3.815895\n2 3.017285 3.904552 2.701771 3.184490 3.452793 4.041790 3.941105 2.784386\n3 2.694613 5.185676 3.239424 2.849002 3.380047 3.552024 5.459776 3.373386\n4 2.923996 3.700341 3.743257 2.534724 2.491844 3.133497 4.393998 2.044624\n     SM145    SM146    SM147    SM149    SM150    SM151    SM152    SM153\n1 3.508677 3.932098 3.826288 5.218724 4.505598 3.618654 3.036380 5.299454\n2 3.243239 2.367279 3.361247 3.248920 2.471650 3.976932 2.552780 2.920620\n3 4.332509 3.322741 4.020953 3.333693 3.206997 5.182178 4.048625 2.303564\n4 2.261019 2.549147 2.286067 4.223450 3.094355 3.044619 2.211586 3.468874\n     SM154    SM155    SM156    SM157    SM158    SM159    SM160    SM161\n1 3.644545 5.138114 2.868427 4.155865 3.716198 4.338230 4.744274 6.316821\n2 3.243389 3.041213 3.809725 2.838223 3.274504 2.212423 2.492858 3.730530\n3 4.509202 2.672747 5.448283 3.450132 4.588278 2.875706 2.802902 3.119339\n4 2.976570 3.791027 3.262451 2.857881 3.735092 2.799343 3.160320 4.661945\n     SM162    SM164    SM165    SM166    SM167    SM168    SM169    SM170\n1 4.338682 3.745385 3.530590 5.218926 4.541468 4.247245 4.532007 3.641164\n2 2.220642 2.230796 2.911672 3.234865 2.580510 2.260701 4.867135 4.202816\n3 2.755081 3.753454 4.258295 3.393463 2.640478 3.433762 6.109715 5.490770\n4 2.813508 2.978225 2.473707 3.704015 3.021116 3.226899 4.090929 3.946722\n     SM171    SM172    SM173    SM174    SM176    SM177    SM179    SM180\n1 3.292972 4.210026 3.991241 4.200521 4.030992 3.448613 4.722028 4.258133\n2 3.559892 2.757707 5.663079 3.037538 2.530864 2.438318 2.673719 2.672059\n3 5.120731 3.314762 7.255712 3.295590 4.196696 4.183756 2.554746 3.690483\n4 3.277343 2.507671 4.747104 2.377601 3.756313 3.022572 2.846991 3.737026\n     SM181    SM182    SM183    SM184    SM185    SM186    SM187    SM188\n1 5.115168 3.989654 4.717125 4.746796 4.813428 3.590884 3.512044 3.920170\n2 2.908065 3.842565 3.124607 3.063896 3.520609 2.419324 3.543039 2.042898\n3 2.636574 4.722798 4.150572 4.372638 5.031470 3.324758 4.960900 3.147702\n4 3.637610 2.702652 4.210475 4.262804 4.709593 2.218548 3.844829 2.889999\n     SM189    SM193    SM194    SM196    SM197    SM198    SM199    SM200\n1 5.076432 4.472432 4.377695 3.712486 4.727070 3.860863 3.875323 3.962574\n2 3.510537 2.493269 3.373699 4.833120 2.470710 4.097068 2.516012 2.141162\n3 2.753970 3.531382 3.872170 6.567699 2.768062 5.441438 3.182296 3.482618\n4 2.986855 3.175477 2.604009 4.134427 3.363315 3.628827 2.605199 3.058773\n\nClustering vector:\nSteptoe   Morex     SM1     SM2     SM3     SM4     SM5     SM6     SM7     SM8 \n      2       1       4       2       2       4       2       1       4       2 \n   SM10    SM11    SM12    SM13    SM14    SM15    SM16    SM20    SM21    SM22 \n      1       1       3       2       2       4       2       2       1       3 \n   SM23    SM24    SM25    SM27    SM30    SM31    SM32    SM35    SM39    SM40 \n      4       4       2       2       4       4       1       4       4       3 \n   SM41    SM42    SM43    SM44    SM45    SM46    SM48    SM50    SM54    SM55 \n      4       2       4       3       1       1       3       2       2       3 \n   SM56    SM57    SM58    SM59    SM61    SM62    SM63    SM64    SM65    SM67 \n      3       4       1       1       1       2       2       2       2       3 \n   SM68    SM69    SM70    SM71    SM72    SM73    SM74    SM75    SM76    SM77 \n      4       2       2       3       3       3       2       2       4       4 \n   SM78    SM79    SM80    SM81    SM82    SM83    SM84    SM85    SM87    SM88 \n      4       2       4       1       1       3       4       2       4       2 \n   SM89    SM91    SM92    SM93    SM94    SM97    SM98    SM99   SM103   SM104 \n      4       4       2       2       2       2       1       4       4       4 \n  SM105   SM110   SM112   SM116   SM120   SM124   SM125   SM126   SM127   SM129 \n      4       2       2       4       2       1       4       3       1       3 \n  SM130   SM131   SM132   SM133   SM134   SM135   SM136   SM137   SM139   SM140 \n      1       3       4       3       1       2       3       1       2       4 \n  SM141   SM142   SM143   SM144   SM145   SM146   SM147   SM149   SM150   SM151 \n      4       3       1       4       4       2       4       3       2       1 \n  SM152   SM153   SM154   SM155   SM156   SM157   SM158   SM159   SM160   SM161 \n      4       3       4       3       1       2       1       2       2       3 \n  SM162   SM164   SM165   SM166   SM167   SM168   SM169   SM170   SM171   SM172 \n      2       2       4       3       2       2       1       1       1       4 \n  SM173   SM174   SM176   SM177   SM179   SM180   SM181   SM182   SM183   SM184 \n      1       4       2       2       2       2       3       4       2       2 \n  SM185   SM186   SM187   SM188   SM189   SM193   SM194   SM196   SM197   SM198 \n      1       4       1       2       3       2       4       1       2       1 \n  SM199   SM200 \n      2       2 \n\nWithin cluster sum of squares by cluster:\n[1] 3988.638 3755.050 2224.519 2803.605\n (between_SS / total_SS =  48.4 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\nWith an increase in groups (k = 4), the value of well grouped data increases to 48.4%, which is a better value than the previous. This indicates that the bigger the value of K, the better the grouping gets."
  },
  {
    "objectID": "index.html#k-means-clustering-visualization",
    "href": "index.html#k-means-clustering-visualization",
    "title": "\nMultivariate Analysis\n",
    "section": "K-Means Clustering Visualization",
    "text": "K-Means Clustering Visualization\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\nlibrary(factoextra) \n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nfviz_cluster(k.means.ID91, data = dat.ID91.sc,              ellipse.type = \"euclid\", repel = TRUE,              labelsize = 8, star.plot=TRUE)\n\n\n\n\n\n\n\n\nThe objective of clustering analysis is to uncover patterns within the dataset. As illustrated in the plot, observations within a group typically share similar characteristics."
  },
  {
    "objectID": "index.html#heres-how-pca-typically-works",
    "href": "index.html#heres-how-pca-typically-works",
    "title": "\nMultivariate Analysis\n",
    "section": "Here’s how PCA typically works",
    "text": "Here’s how PCA typically works\n\nStandardization: If the variables in the dataset are measured on different scales, PCA often starts with standardizing the data to have a mean of 0 and a standard deviation of 1.\nCovariance Matrix: PCA calculates the covariance matrix of the standardized data. This matrix summarizes the relationships between pairs of variables, indicating how much they vary together.\nEigenvalue Decomposition: PCA then decomposes the covariance matrix into its eigenvectors and eigenvalues. The eigenvectors represent the directions of maximum variance in the data, and the corresponding eigenvalues indicate the magnitude of variance along those directions.\nSelecting Principal Components: The eigenvectors are ranked based on their corresponding eigenvalues, with the first eigenvector capturing the most variance, the second capturing the second most variance, and so on. Typically, only a subset of the top-ranked eigenvectors, called principal components, are retained, thereby reducing the dimensionality of the dataset.\nDimensionality Reduction: By projecting the original data onto the selected principal components, PCA creates a lower-dimensional representation of the dataset while preserving as much of the variance as possible. This reduced representation can often capture the essential patterns and structures in the data."
  },
  {
    "objectID": "index.html#application-of-pca",
    "href": "index.html#application-of-pca",
    "title": "\nMultivariate Analysis\n",
    "section": "Application of PCA",
    "text": "Application of PCA\n\nDimensionality Reduction: PCA can reduce the number of variables in a dataset while retaining most of the variance, making it easier to analyze and visualize high-dimensional data.\nData Visualization: PCA can be used to visualize high-dimensional data in lower dimensions (e.g., 2D or 3D), allowing for easier interpretation and exploration of data patterns.\nFeature Extraction: PCA can extract new features (principal components) that are linear combinations of the original variables. These new features may capture important underlying patterns in the data.\n\nOverall, PCA is a versatile tool widely used in various fields such as statistics, machine learning, finance, image processing, and genetics for data preprocessing, visualization, and feature extraction."
  },
  {
    "objectID": "index.html#example-2",
    "href": "index.html#example-2",
    "title": "\nMultivariate Analysis\n",
    "section": "Example",
    "text": "Example\nLet’s consider the australia.soybean.csv, a multi-environment trial of 58 varieties of soybeans, in 4 locations across 2 years in Australia. The description of the data are:\n\nenv (environment), 8 levels,\nloc (location)\nyear\ngen (genotype) of soybeans,\nyield, metric tons/hectare\nheight, in meters\nlodging, number of plants\nsize seed, in millimetres\nprotein, percentage\noil, percentage\n\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\nlibrary(tidyverse) \ndat &lt;- read_csv(\"australia.soybean.csv\")\n\nRows: 464 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): env, loc, gen\ndbl (7): year, yield, height, lodging, size, protein, oil\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nTo study the relationship between two variables, say yield and oil, we can use + Pearson correlation coefficient + Simple linear regression\n\n#|#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\n#|echo = FALSE\n\nggplot(dat) +   \n  aes(x = oil, y = yield) +   \n  geom_point() +   \n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n The diagram above indicates a positive linear relationship between yield and oil content of soybeans.\nLets consider one location Brookstead in the australia.soybean data\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\n#|message = FALSE\ndat.Brookstead &lt;- dat %&gt;%   \n  filter(loc==\"Brookstead\") \nstr(dat.Brookstead)\n\nspc_tbl_ [116 × 10] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ env    : chr [1:116] \"B70\" \"B70\" \"B70\" \"B70\" ...\n $ loc    : chr [1:116] \"Brookstead\" \"Brookstead\" \"Brookstead\" \"Brookstead\" ...\n $ year   : num [1:116] 1970 1970 1970 1970 1970 1970 1970 1970 1970 1970 ...\n $ gen    : chr [1:116] \"G01\" \"G02\" \"G03\" \"G04\" ...\n $ yield  : num [1:116] 1.253 1.167 0.468 1.445 1.338 ...\n $ height : num [1:116] 1.01 1.13 1.16 1.24 1.12 ...\n $ lodging: num [1:116] 3.25 2.75 2.25 1.5 2 2.25 2 2.25 1.75 2 ...\n $ size   : num [1:116] 8.85 8.9 10.8 10.6 11.95 ...\n $ protein: num [1:116] 39.5 38.6 37.8 38.7 37.8 ...\n $ oil    : num [1:116] 18.9 19.8 20.4 20.4 20.8 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   env = col_character(),\n  ..   loc = col_character(),\n  ..   year = col_double(),\n  ..   gen = col_character(),\n  ..   yield = col_double(),\n  ..   height = col_double(),\n  ..   lodging = col_double(),\n  ..   size = col_double(),\n  ..   protein = col_double(),\n  ..   oil = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nWe store the names of the genotypes in a vector\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\nlabels.gen &lt;- dat.Brookstead$gen\n\nAnd only consider the quantitative variables\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.Brookstead &lt;- dat.Brookstead %&gt;%  \n  select(-c(env, loc, year, gen))\n\nWe run the PCA using the prcomp function\n\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\ndat.Brookstead.pca&lt;-prcomp(dat.Brookstead, center=TRUE, scale=TRUE) \nsummary(dat.Brookstead.pca)\n\nImportance of components:\n                          PC1    PC2    PC3     PC4     PC5     PC6\nStandard deviation     1.8780 0.9949 0.9176 0.60462 0.42702 0.30580\nProportion of Variance 0.5878 0.1650 0.1403 0.06093 0.03039 0.01559\nCumulative Proportion  0.5878 0.7528 0.8931 0.95402 0.98441 1.00000\n\n\nThe first 2 axes explain more than 75% of the variation in the dataset. We visualize the PCA using a biplot. A biplot is a type of graph that allows us to simultaneously visualize the observations and the variables. We use the ggbiplot package to visualize the biplot.\n\n#|eval=FALSE\n#|tidy=FALSE\n#|size='tiny'\nlibrary(ggbiplot) \nggbiplot(dat.Brookstead.pca) +   \n  labs(title = \"Yield and other traits of soybeans in Australia\",        subtitle = \"Period 1970-1971\",        caption = \"Data: agridat::australia.soybean\"   ) +  \n  theme_classic()\n\n\n\n\n\n\n\n\n\nThe components are seen as arrows coming from the origin. Here, all the variables contribute to PC1, with:\n\nhigher values of oil, size and yield to the right on this graph and lower values to the left\nvice versa for protein, lodging and height\n\nThis allows us to see how the observations relate to the components. However, this is not very informative if we do not identify the observations. We can display the names of the genotypes.\n\n#|eval=FALSE\n#|tidy=FALSE\n#|size='tiny'\nlibrary(ggbiplot) \nggbiplot(dat.Brookstead.pca, labels=labels.gen) + #&lt;&lt;\n  labs(title = \"Yield and other traits of soybeans in Australia\",        subtitle = \"Period 1970-1971\",        caption = \"Data: agridat::australia.soybean\"   ) +   \n  theme_classic()\n\n\n\n\n\n\n\n\n\nThe diagram shows in detail the observations per each genotype.\nWe have two years of testing, 1970 and 1971. Could be interesting to identify the genotypes by year\n\n#|eval=FALSE\n#|tidy=FALSE\n#|size='tiny'\nlibrary(ggbiplot) \n#ggbiplot(dat.Brookstead.pca, labels=labels.gen, groups=labels.year)+ #&lt;&lt;   \n  #labs(title = \"Yield and other traits of soybeans in Australia\",        subtitle = \"Period 1970-1971\",        caption = \"Data: agridat::australia.soybean\"   ) +\n  #theme_classic()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]